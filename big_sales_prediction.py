# -*- coding: utf-8 -*-
"""Big Sales Prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1yXbCIgZ6fZCuUTsJdXTeD1lKiCMmtiYB

# **Big Sales Prediction using Random Forest Regressor**

## **IMPORT LIBRARY**
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

"""## **IMPORT CSV**"""

df = pd.read_csv(r'https://raw.githubusercontent.com/YBI-Foundation/Dataset/main/Big%20Sales%20Data.csv')
df.head()

"""## **INFORMATION OF DATAFRAME**"""

df.info()

"""## **COLUMNS OF DATA FRAME**"""

df.columns

"""## **DESCRIBING DATA FRAME**"""

df.describe()

df['Item_Weight'].fillna(df.groupby(['Item_Type'])['Item_Weight'].transform('mean'), inplace=True)
df.info()

df.describe()

"""## **PAIR PLOT**"""

sns.pairplot(df)

df[['Item_Identifier']].value_counts()

"""## **NORMALIZING Item_Fat_Content**"""

df[['Item_Fat_Content']].value_counts()

df.replace({'Item_Fat_Content': {'LF':'Low Fat', 'reg': 'Regular', 'low fat':'Low Fat'}}, inplace=True)
df[['Item_Fat_Content']].value_counts()

df.replace({'Item_Fat_Content': {'Low Fat': 0, 'Regular' : 1}}, inplace=True)
df[['Item_Fat_Content']].value_counts()

"""## **NORMALIZING Outlet_Type**"""

df[['Item_Type']].value_counts()

df.replace({'Item_Type': {'Fruits and Vegetables':0, 'Snack Foods':0, 'Household':1,
'Frozen Foods' : 0, 'Dairy' : 0, 'Baking Goods' : 0,
'Canned' : 0, 'Health and Hygiene' : 1,
'Meat' : 0, 'Soft Drinks' : 0, 'Breads' : 0, 'Hard Drinks' : 0,
'Others' : 2, 'Starchy Foods' : 0, 'Breakfast' : 0, 'Seafood' : 0
}},inplace=True)

df[['Item_Type']].value_counts()

"""## **NORMALIZING Outlet_Identifier**"""

df[['Outlet_Identifier']].value_counts()

df.replace({'Outlet_Identifier':{'OUT027': 0, 'OUT013': 1,
'OUT049' : 2, 'OUT046' : 3, 'OUT035' : 4,
'OUT045' : 5, 'OUT018' : 6,
'OUT017' : 7, 'OUT010' : 8, 'OUT019' : 9,
}},inplace=True)
df[['Outlet_Identifier']].value_counts()

"""## **NORMALIZING Outlet_Size**"""

df[['Outlet_Size']].value_counts()

df.replace({'Outlet_Size': {'Small': 0, 'Medium' : 1, 'High' : 2}}, inplace=True)

df[['Outlet_Size']].value_counts()

"""## **NORMALIZING Outlet_Location_Type**"""

df[['Outlet_Location_Type']].value_counts()

df.replace({'Outlet_Location_Type': {'Tier 1': 0,'Tier 2' : 1, 'Tier 3' : 2}}, inplace=True)

df[['Outlet_Location_Type']].value_counts()

"""## **NORMALIZING Outlet_Type**"""

df[['Outlet_Type']].value_counts()

df.replace({'Outlet_Type': {'Grocery Store': 0, 'Supermarket Type1' : 1, 'Supermarket Type2' : 2, 'Supermarket Type3': 3}}, inplace=True)
df[['Outlet_Type']].value_counts()

"""## **NORMALIZED DATA**"""

df.head()

df.info()

df.shape

"""## **Y DATA**"""

y=df['Item_Outlet_Sales']
y.shape

y

"""## **X DATA**"""

X=df.drop(['Item_Identifier',"Item_Outlet_Sales"],axis=1)
X.shape

X

"""## **STANDARDIZING DATA**"""

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
X_std = df[['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year' ]]
X_std = sc.fit_transform(X_std)
X_std

"""## **MERGING STANDARDISED DATA IN DATAFRAME**"""

X[['Item_Weight', 'Item_Visibility', 'Item_MRP', 'Outlet_Establishment_Year' ]] = pd.DataFrame(X_std, columns= [['Item_Weight', 'Item_Visibility','Item_MRP', 'Outlet_Establishment_Year']])
X

"""## **SPLITTING TRAIN AND TEST DATA**"""

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.1, random_state=2529)

X_train.shape, X_test.shape, y_train.shape, y_test.shape

"""## **Fitting MODEL**"""

from sklearn.ensemble import RandomForestRegressor

rfr = RandomForestRegressor(random_state=2529)
rfr.fit(X_train,y_train)

y_pred = rfr.predict(X_test)
y_pred.shape

y_pred

"""## **METRICS**"""

from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

mean_squared_error(y_test,y_pred)

mean_absolute_error(y_test, y_pred)

r2_score(y_test,y_pred)

"""## **Actual Price vs Predicted Price**"""